{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Data Cleaning and Preprocessing\n",
    "\n",
    "## Objectives\n",
    "- Handle missing values appropriately\n",
    "- Remove sparse features\n",
    "- Encode categorical variables\n",
    "- Prepare data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sararosati/Desktop/vscode-projects/Heritage-Housing/Heritage-housing/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/sararosati/Desktop/vscode-projects/Heritage-Housing/Heritage-housing'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main dataset shape: (1460, 24)\n",
      "Inherited houses shape: (4, 23)\n",
      "\n",
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "df = pd.read_csv('inputs/datasets/house_prices_records.csv')\n",
    "inherited_df = pd.read_csv('inputs/datasets/inherited_houses.csv')\n",
    "\n",
    "print(f\"Main dataset shape: {df.shape}\")\n",
    "print(f\"Inherited houses shape: {inherited_df.shape}\")\n",
    "print(\"\\nDataset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with >80% missing values:\n",
      "EnclosedPorch    90.684932\n",
      "WoodDeckSF       89.383562\n",
      "dtype: float64\n",
      "\n",
      "Dataset shape after dropping sparse features: (1460, 22)\n",
      "Features removed: ['EnclosedPorch', 'WoodDeckSF']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Drop features with >80% missing values\n",
    "print(\"Features with >80% missing values:\")\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "sparse_features = missing_percentage[missing_percentage > 80]\n",
    "print(sparse_features)\n",
    "\n",
    "# Drop these sparse features\n",
    "df_cleaned = df.drop(columns=sparse_features.index)\n",
    "\n",
    "print(f\"\\nDataset shape after dropping sparse features: {df_cleaned.shape}\")\n",
    "print(f\"Features removed: {list(sparse_features.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Handle Remaining Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing values:\n",
      "2ndFlrSF         86\n",
      "BedroomAbvGr     99\n",
      "BsmtExposure     38\n",
      "BsmtFinType1    145\n",
      "GarageFinish    235\n",
      "GarageYrBlt      81\n",
      "LotFrontage     259\n",
      "MasVnrArea        8\n",
      "dtype: int64\n",
      "\n",
      "==================================================\n",
      "Filled 2ndFlrSF with median: 0.0\n",
      "Filled BedroomAbvGr with median: 3.0\n",
      "Filled GarageYrBlt with median: 1980.0\n",
      "Filled LotFrontage with median: 69.0\n",
      "Filled MasVnrArea with median: 0.0\n",
      "Filled BsmtExposure with mode: No\n",
      "Filled BsmtFinType1 with mode: Unf\n",
      "Filled GarageFinish with mode: Unf\n",
      "\n",
      "==================================================\n",
      "Verification - remaining missing values:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check remaining missing values\n",
    "print(\"Remaining missing values:\")\n",
    "remaining_missing = df_cleaned.isnull().sum()\n",
    "remaining_missing = remaining_missing[remaining_missing > 0]\n",
    "print(remaining_missing)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Strategy for each column:\n",
    "# - LotFrontage: Fill with median (continuous variable)\n",
    "# - BedroomAbvGr, 2ndFlrSF, GarageYrBlt: Fill with median\n",
    "# - Categorical columns: Fill with mode (most frequent value)\n",
    "\n",
    "# Fill numeric missing values with median\n",
    "numeric_cols_missing = df_cleaned.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols_missing:\n",
    "    if df_cleaned[col].isnull().sum() > 0:\n",
    "        median_value = df_cleaned[col].median()\n",
    "        df_cleaned[col].fillna(median_value, inplace=True)\n",
    "        print(f\"Filled {col} with median: {median_value}\")\n",
    "\n",
    "# Fill categorical missing values with mode\n",
    "categorical_cols = df_cleaned.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if df_cleaned[col].isnull().sum() > 0:\n",
    "        mode_value = df_cleaned[col].mode()[0]\n",
    "        df_cleaned[col].fillna(mode_value, inplace=True)\n",
    "        print(f\"Filled {col} with mode: {mode_value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Verification - remaining missing values:\")\n",
    "print(df_cleaned.isnull().sum().sum())  # Should be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns to encode: ['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual']\n",
      "Encoded BsmtExposure: {'Av': 0, 'Gd': 1, 'Mn': 2, 'No': 3}\n",
      "Encoded BsmtFinType1: {'ALQ': 0, 'BLQ': 1, 'GLQ': 2, 'LwQ': 3, 'Rec': 4, 'Unf': 5}\n",
      "Encoded GarageFinish: {'Fin': 0, 'RFn': 1, 'Unf': 2}\n",
      "Encoded KitchenQual: {'Ex': 0, 'Fa': 1, 'Gd': 2, 'TA': 3}\n",
      "\n",
      "==================================================\n",
      "All categorical variables successfully encoded!\n",
      "Dataset shape: (1460, 22)\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df_cleaned.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical columns to encode: {categorical_cols}\")\n",
    "\n",
    "# Apply Label Encoding to categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_cleaned[col] = le.fit_transform(df_cleaned[col])\n",
    "    label_encoders[col] = le\n",
    "    print(f\"Encoded {col}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"All categorical variables successfully encoded!\")\n",
    "print(f\"Dataset shape: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation Summary:\n",
      "Features shape: (1460, 21)\n",
      "Target shape: (1460,)\n",
      "\n",
      "Feature columns (21):\n",
      "['1stFlrSF', '2ndFlrSF', 'BedroomAbvGr', 'BsmtExposure', 'BsmtFinSF1', 'BsmtFinType1', 'BsmtUnfSF', 'GarageArea', 'GarageFinish', 'GarageYrBlt', 'GrLivArea', 'KitchenQual', 'LotArea', 'LotFrontage', 'MasVnrArea', 'OpenPorchSF', 'OverallCond', 'OverallQual', 'TotalBsmtSF', 'YearBuilt', 'YearRemodAdd']\n",
      "\n",
      "Target variable statistics:\n",
      "count      1460.000000\n",
      "mean     180921.195890\n",
      "std       79442.502883\n",
      "min       34900.000000\n",
      "25%      129975.000000\n",
      "50%      163000.000000\n",
      "75%      214000.000000\n",
      "max      755000.000000\n",
      "Name: SalePrice, dtype: float64\n",
      "\n",
      "==================================================\n",
      "Data is ready for model training!\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = df_cleaned.drop('SalePrice', axis=1)\n",
    "y = df_cleaned['SalePrice']\n",
    "\n",
    "print(\"Data Preparation Summary:\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns ({X.shape[1]}):\")\n",
    "print(X.columns.tolist())\n",
    "print(f\"\\nTarget variable statistics:\")\n",
    "print(y.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Data is ready for model training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 'outputs' directory\n",
      "Cleaned dataset saved to: outputs/X_y_cleaned.csv\n",
      "\n",
      "All files saved successfully!\n",
      "X shape: (1460, 21)\n",
      "y shape: (1460,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create outputs directory if it doesn't exist\n",
    "if not os.path.exists('outputs'):\n",
    "    os.makedirs('outputs')\n",
    "    print(\"Created 'outputs' directory\")\n",
    "\n",
    "# Now save the cleaned dataset\n",
    "df_cleaned.to_csv('outputs/X_y_cleaned.csv', index=False)\n",
    "print(\"Cleaned dataset saved to: outputs/X_y_cleaned.csv\")\n",
    "\n",
    "# Also save X and y separately\n",
    "X.to_csv('outputs/X.csv', index=False)\n",
    "y.to_csv('outputs/y.csv', index=False)\n",
    "\n",
    "print(\"\\nAll files saved successfully!\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
